{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requisitos\n",
    "# IMPORTANTE: En Windows Utilizar Python de 3.6 a 3.9, es requisito de tensorflow\n",
    "# https://graphviz.gitlab.io/download/\n",
    "!pip install pydot\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install cuda-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zwBCE43Cv3PH"
   },
   "source": [
    "##### Copyright 2019 The TensorFlow Authors.\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:48.666478Z",
     "iopub.status.busy": "2023-09-30T01:24:48.665933Z",
     "iopub.status.idle": "2023-09-30T01:24:48.669995Z",
     "shell.execute_reply": "2023-09-30T01:24:48.669450Z"
    },
    "id": "fOad0I2cv569"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQB7yiF6v9GR"
   },
   "source": [
    "# Load a pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oqa952X4wQKK"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/load_data/pandas_dataframe\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/load_data/pandas_dataframe.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/pandas_dataframe.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/load_data/pandas_dataframe.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UmyEaf4Awl2v"
   },
   "source": [
    "This tutorial provides examples of how to load <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\" class=\"external\">pandas DataFrames</a> into TensorFlow.\n",
    "\n",
    "You will use a small <a href=\"https://archive.ics.uci.edu/ml/datasets/heart+Disease\" class=\"external\">heart disease dataset</a> provided by the UCI Machine Learning Repository. There are several hundred rows in the CSV. Each row describes a patient, and each column describes an attribute. You will use this information to predict whether a patient has heart disease, which is a binary classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiyC7HkqxlUD"
   },
   "source": [
    "## Read data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:48.673816Z",
     "iopub.status.busy": "2023-09-30T01:24:48.673225Z",
     "iopub.status.idle": "2023-09-30T01:24:51.013416Z",
     "shell.execute_reply": "2023-09-30T01:24:51.012726Z"
    },
    "id": "5IoRbCA2n0_V"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "SHUFFLE_BUFFER = 500\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6BXRPD2-xtQ1"
   },
   "source": [
    "Read the CSV file using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:51.095840Z",
     "iopub.status.busy": "2023-09-30T01:24:51.095279Z",
     "iopub.status.idle": "2023-09-30T01:24:51.101266Z",
     "shell.execute_reply": "2023-09-30T01:24:51.100707Z"
    },
    "id": "UEfJ8TcMpe-2"
   },
   "outputs": [],
   "source": [
    "csv_file = os.path.join('..', '..', 'data', 'fact_licitacion-2007_2023-sonda.csv')\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4K873P-Pp8c7"
   },
   "source": [
    "This is what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:51.104836Z",
     "iopub.status.busy": "2023-09-30T01:24:51.104309Z",
     "iopub.status.idle": "2023-09-30T01:24:51.117243Z",
     "shell.execute_reply": "2023-09-30T01:24:51.116656Z"
    },
    "id": "8FkK6QIRpjd4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_fecha</th>\n",
       "      <th>id_rubro</th>\n",
       "      <th>rubro</th>\n",
       "      <th>id_sector</th>\n",
       "      <th>id_organismo</th>\n",
       "      <th>id_unidad</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>producto</th>\n",
       "      <th>is_proveedor</th>\n",
       "      <th>id_zona</th>\n",
       "      <th>codigo_moneda</th>\n",
       "      <th>cantidad_adjudicada</th>\n",
       "      <th>monto_unitario_oferta_usd</th>\n",
       "      <th>monto_adjudicado_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160720</td>\n",
       "      <td>427</td>\n",
       "      <td>APRENDIZAJE A DISTANCIA</td>\n",
       "      <td>4</td>\n",
       "      <td>6958</td>\n",
       "      <td>3074</td>\n",
       "      <td>86111501</td>\n",
       "      <td>ORIENTACION A DISTANCIA</td>\n",
       "      <td>24987</td>\n",
       "      <td>13115</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24146.576</td>\n",
       "      <td>24146.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170426</td>\n",
       "      <td>427</td>\n",
       "      <td>APRENDIZAJE A DISTANCIA</td>\n",
       "      <td>4</td>\n",
       "      <td>7230</td>\n",
       "      <td>2607</td>\n",
       "      <td>86111501</td>\n",
       "      <td>ORIENTACION A DISTANCIA</td>\n",
       "      <td>301528</td>\n",
       "      <td>13101</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25952.099</td>\n",
       "      <td>25952.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180418</td>\n",
       "      <td>427</td>\n",
       "      <td>APRENDIZAJE A DISTANCIA</td>\n",
       "      <td>4</td>\n",
       "      <td>7230</td>\n",
       "      <td>2607</td>\n",
       "      <td>86111501</td>\n",
       "      <td>ORIENTACION A DISTANCIA</td>\n",
       "      <td>301528</td>\n",
       "      <td>13101</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24977.203</td>\n",
       "      <td>24977.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20191129</td>\n",
       "      <td>427</td>\n",
       "      <td>APRENDIZAJE A DISTANCIA</td>\n",
       "      <td>5</td>\n",
       "      <td>114395</td>\n",
       "      <td>4226</td>\n",
       "      <td>86111501</td>\n",
       "      <td>ORIENTACION A DISTANCIA</td>\n",
       "      <td>966309</td>\n",
       "      <td>8312</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170.296</td>\n",
       "      <td>170.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210924</td>\n",
       "      <td>427</td>\n",
       "      <td>APRENDIZAJE A DISTANCIA</td>\n",
       "      <td>4</td>\n",
       "      <td>6950</td>\n",
       "      <td>1581</td>\n",
       "      <td>86111501</td>\n",
       "      <td>ORIENTACION A DISTANCIA</td>\n",
       "      <td>235872</td>\n",
       "      <td>13101</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104016.431</td>\n",
       "      <td>104016.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391255</th>\n",
       "      <td>20230607</td>\n",
       "      <td>2467</td>\n",
       "      <td>SOFTWARE DE SEGURIDAD Y PROTECCION</td>\n",
       "      <td>1</td>\n",
       "      <td>7127</td>\n",
       "      <td>2862</td>\n",
       "      <td>43233205</td>\n",
       "      <td>SOFTWARE DE PROTECCION ANTIVIRUS Y DE SEGURIDA...</td>\n",
       "      <td>839304</td>\n",
       "      <td>13101</td>\n",
       "      <td>2</td>\n",
       "      <td>630.0</td>\n",
       "      <td>13.231</td>\n",
       "      <td>8335.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391256</th>\n",
       "      <td>20230616</td>\n",
       "      <td>2467</td>\n",
       "      <td>SOFTWARE DE SEGURIDAD Y PROTECCION</td>\n",
       "      <td>5</td>\n",
       "      <td>115285</td>\n",
       "      <td>4487</td>\n",
       "      <td>43233205</td>\n",
       "      <td>SOFTWARE DE PROTECCION ANTIVIRUS Y DE SEGURIDA...</td>\n",
       "      <td>802530</td>\n",
       "      <td>8104</td>\n",
       "      <td>2</td>\n",
       "      <td>200.0</td>\n",
       "      <td>31.242</td>\n",
       "      <td>6248.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391257</th>\n",
       "      <td>20230616</td>\n",
       "      <td>2467</td>\n",
       "      <td>SOFTWARE DE SEGURIDAD Y PROTECCION</td>\n",
       "      <td>4</td>\n",
       "      <td>1042394</td>\n",
       "      <td>519302</td>\n",
       "      <td>43233205</td>\n",
       "      <td>SOFTWARE DE PROTECCION ANTIVIRUS Y DE SEGURIDA...</td>\n",
       "      <td>256306</td>\n",
       "      <td>13101</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8800.000</td>\n",
       "      <td>8800.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391258</th>\n",
       "      <td>20230616</td>\n",
       "      <td>2467</td>\n",
       "      <td>SOFTWARE DE SEGURIDAD Y PROTECCION</td>\n",
       "      <td>5</td>\n",
       "      <td>135562</td>\n",
       "      <td>5282</td>\n",
       "      <td>43233205</td>\n",
       "      <td>SOFTWARE DE PROTECCION ANTIVIRUS Y DE SEGURIDA...</td>\n",
       "      <td>787184</td>\n",
       "      <td>16107</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10911.739</td>\n",
       "      <td>10911.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391259</th>\n",
       "      <td>20230622</td>\n",
       "      <td>2467</td>\n",
       "      <td>SOFTWARE DE SEGURIDAD Y PROTECCION</td>\n",
       "      <td>5</td>\n",
       "      <td>89591</td>\n",
       "      <td>3494</td>\n",
       "      <td>43233205</td>\n",
       "      <td>SOFTWARE DE PROTECCION ANTIVIRUS Y DE SEGURIDA...</td>\n",
       "      <td>666809</td>\n",
       "      <td>7108</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3359.765</td>\n",
       "      <td>3359.765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391260 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_fecha  id_rubro                               rubro  id_sector  \\\n",
       "0       20160720       427             APRENDIZAJE A DISTANCIA          4   \n",
       "1       20170426       427             APRENDIZAJE A DISTANCIA          4   \n",
       "2       20180418       427             APRENDIZAJE A DISTANCIA          4   \n",
       "3       20191129       427             APRENDIZAJE A DISTANCIA          5   \n",
       "4       20210924       427             APRENDIZAJE A DISTANCIA          4   \n",
       "...          ...       ...                                 ...        ...   \n",
       "391255  20230607      2467  SOFTWARE DE SEGURIDAD Y PROTECCION          1   \n",
       "391256  20230616      2467  SOFTWARE DE SEGURIDAD Y PROTECCION          5   \n",
       "391257  20230616      2467  SOFTWARE DE SEGURIDAD Y PROTECCION          4   \n",
       "391258  20230616      2467  SOFTWARE DE SEGURIDAD Y PROTECCION          5   \n",
       "391259  20230622      2467  SOFTWARE DE SEGURIDAD Y PROTECCION          5   \n",
       "\n",
       "        id_organismo  id_unidad  id_producto  \\\n",
       "0               6958       3074     86111501   \n",
       "1               7230       2607     86111501   \n",
       "2               7230       2607     86111501   \n",
       "3             114395       4226     86111501   \n",
       "4               6950       1581     86111501   \n",
       "...              ...        ...          ...   \n",
       "391255          7127       2862     43233205   \n",
       "391256        115285       4487     43233205   \n",
       "391257       1042394     519302     43233205   \n",
       "391258        135562       5282     43233205   \n",
       "391259         89591       3494     43233205   \n",
       "\n",
       "                                                 producto  is_proveedor  \\\n",
       "0                                 ORIENTACION A DISTANCIA         24987   \n",
       "1                                 ORIENTACION A DISTANCIA        301528   \n",
       "2                                 ORIENTACION A DISTANCIA        301528   \n",
       "3                                 ORIENTACION A DISTANCIA        966309   \n",
       "4                                 ORIENTACION A DISTANCIA        235872   \n",
       "...                                                   ...           ...   \n",
       "391255  SOFTWARE DE PROTECCION ANTIVIRUS Y DE SEGURIDA...        839304   \n",
       "391256  SOFTWARE DE PROTECCION ANTIVIRUS Y DE SEGURIDA...        802530   \n",
       "391257  SOFTWARE DE PROTECCION ANTIVIRUS Y DE SEGURIDA...        256306   \n",
       "391258  SOFTWARE DE PROTECCION ANTIVIRUS Y DE SEGURIDA...        787184   \n",
       "391259  SOFTWARE DE PROTECCION ANTIVIRUS Y DE SEGURIDA...        666809   \n",
       "\n",
       "        id_zona  codigo_moneda  cantidad_adjudicada  \\\n",
       "0         13115              2                  1.0   \n",
       "1         13101              2                  1.0   \n",
       "2         13101              2                  1.0   \n",
       "3          8312              2                  1.0   \n",
       "4         13101              2                  1.0   \n",
       "...         ...            ...                  ...   \n",
       "391255    13101              2                630.0   \n",
       "391256     8104              2                200.0   \n",
       "391257    13101              3                  1.0   \n",
       "391258    16107              2                  1.0   \n",
       "391259     7108              2                  1.0   \n",
       "\n",
       "        monto_unitario_oferta_usd  monto_adjudicado_usd  \n",
       "0                       24146.576             24146.576  \n",
       "1                       25952.099             25952.099  \n",
       "2                       24977.203             24977.203  \n",
       "3                         170.296               170.296  \n",
       "4                      104016.431            104016.431  \n",
       "...                           ...                   ...  \n",
       "391255                     13.231              8335.891  \n",
       "391256                     31.242              6248.496  \n",
       "391257                   8800.000              8800.000  \n",
       "391258                  10911.739             10911.739  \n",
       "391259                   3359.765              3359.765  \n",
       "\n",
       "[391260 rows x 14 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:51.120558Z",
     "iopub.status.busy": "2023-09-30T01:24:51.120047Z",
     "iopub.status.idle": "2023-09-30T01:24:51.124912Z",
     "shell.execute_reply": "2023-09-30T01:24:51.124344Z"
    },
    "id": "_MOAKz654CT5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_fecha                       int64\n",
       "id_rubro                       int64\n",
       "rubro                         object\n",
       "id_sector                      int64\n",
       "id_organismo                   int64\n",
       "id_unidad                      int64\n",
       "id_producto                    int64\n",
       "producto                      object\n",
       "is_proveedor                   int64\n",
       "id_zona                        int64\n",
       "codigo_moneda                  int64\n",
       "cantidad_adjudicada          float64\n",
       "monto_unitario_oferta_usd    float64\n",
       "monto_adjudicado_usd         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jVyGjKvnqGlb"
   },
   "source": [
    "You will build models to predict the label contained in the `target` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# las columnas que voy a utilizar\n",
    "usable_column_names = ['id_fecha', 'id_producto', 'monto_adjudicado_usd']\n",
    "# columnas descartadas: 'id_unidad', 'id_zona', 'id_rubro', 'rubro', 'id_sector', 'id_organismo', 'producto', 'id_proveedor', 'codigo_moneda', 'cantidad_adjudicada', 'monto_unitario_oferta_usd', \n",
    "df = df[usable_column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_fecha</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>monto_adjudicado_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160720</td>\n",
       "      <td>86111501</td>\n",
       "      <td>24146.576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20170426</td>\n",
       "      <td>86111501</td>\n",
       "      <td>25952.099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180418</td>\n",
       "      <td>86111501</td>\n",
       "      <td>24977.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20191129</td>\n",
       "      <td>86111501</td>\n",
       "      <td>170.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210924</td>\n",
       "      <td>86111501</td>\n",
       "      <td>104016.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391255</th>\n",
       "      <td>20230607</td>\n",
       "      <td>43233205</td>\n",
       "      <td>8335.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391256</th>\n",
       "      <td>20230616</td>\n",
       "      <td>43233205</td>\n",
       "      <td>6248.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391257</th>\n",
       "      <td>20230616</td>\n",
       "      <td>43233205</td>\n",
       "      <td>8800.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391258</th>\n",
       "      <td>20230616</td>\n",
       "      <td>43233205</td>\n",
       "      <td>10911.739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391259</th>\n",
       "      <td>20230622</td>\n",
       "      <td>43233205</td>\n",
       "      <td>3359.765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>391260 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_fecha  id_producto  monto_adjudicado_usd\n",
       "0       20160720     86111501             24146.576\n",
       "1       20170426     86111501             25952.099\n",
       "2       20180418     86111501             24977.203\n",
       "3       20191129     86111501               170.296\n",
       "4       20210924     86111501            104016.431\n",
       "...          ...          ...                   ...\n",
       "391255  20230607     43233205              8335.891\n",
       "391256  20230616     43233205              6248.496\n",
       "391257  20230616     43233205              8800.000\n",
       "391258  20230616     43233205             10911.739\n",
       "391259  20230622     43233205              3359.765\n",
       "\n",
       "[391260 rows x 3 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_feature_names = [] # no tengo columnas binarias\n",
    "categorical_feature_names = ['id_unidad', 'id_producto', 'id_zona']\n",
    "numeric_feature_names = ['id_fecha','monto_adjudicado_usd']\n",
    "target_column_name = 'monto_adjudicado_usd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promedio: 145561.77279975978\n",
      "Desviación estándar: 26044495.53225069\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Supongamos que tienes un DataFrame llamado df y quieres calcular para la columna 'columna_deseada'\n",
    "# Calcula el promedio\n",
    "promedio = df[target_column_name].mean()\n",
    "\n",
    "# Calcula la desviación estándar\n",
    "desviacion_estandar = df[target_column_name].std()\n",
    "\n",
    "# Imprime el promedio y la desviación estándar\n",
    "print(f'Promedio: {promedio}')\n",
    "print(f'Desviación estándar: {desviacion_estandar}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_unidad</th>\n",
       "      <th>id_producto</th>\n",
       "      <th>id_zona</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1005</th>\n",
       "      <th>45121518</th>\n",
       "      <th>1101</th>\n",
       "      <td>726.691000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52161518</th>\n",
       "      <th>1101</th>\n",
       "      <td>5426.421000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52161523</th>\n",
       "      <th>1101</th>\n",
       "      <td>1053.124000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80111504</th>\n",
       "      <th>1101</th>\n",
       "      <td>2561.958792</td>\n",
       "      <td>2004.777326</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80111715</th>\n",
       "      <th>1101</th>\n",
       "      <td>70789.672550</td>\n",
       "      <td>59274.552775</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">1271359</th>\n",
       "      <th>43212110</th>\n",
       "      <th>13302</th>\n",
       "      <td>18014.602000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45121501</th>\n",
       "      <th>13302</th>\n",
       "      <td>6753.030000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52161542</th>\n",
       "      <th>13302</th>\n",
       "      <td>4410.703000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272565</th>\n",
       "      <th>43231512</th>\n",
       "      <th>1107</th>\n",
       "      <td>3443.011000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1287871</th>\n",
       "      <th>80111504</th>\n",
       "      <th>9114</th>\n",
       "      <td>7438.686000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84656 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       mean           std  count\n",
       "id_unidad id_producto id_zona                                   \n",
       "1005      45121518    1101       726.691000           NaN      1\n",
       "          52161518    1101      5426.421000           NaN      1\n",
       "          52161523    1101      1053.124000           NaN      1\n",
       "          80111504    1101      2561.958792   2004.777326     24\n",
       "          80111715    1101     70789.672550  59274.552775     20\n",
       "...                                     ...           ...    ...\n",
       "1271359   43212110    13302    18014.602000           NaN      1\n",
       "          45121501    13302     6753.030000           NaN      1\n",
       "          52161542    13302     4410.703000           NaN      1\n",
       "1272565   43231512    1107      3443.011000           NaN      1\n",
       "1287871   80111504    9114      7438.686000           NaN      1\n",
       "\n",
       "[84656 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42107"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = df.groupby(['id_unidad', 'id_producto'])[target_column_name].agg(['mean', 'std', 'count'])\n",
    "(resultados['count'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13400"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = df.groupby(['id_producto', 'id_zona'])[target_column_name].agg(['mean', 'std', 'count'])\n",
    "(resultados['count'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = df.groupby(['id_producto'])[target_column_name].agg(['mean', 'std', 'count'])\n",
    "(resultados['count'] == 1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados.to_csv('resultados_agrupados.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df.pop('cantidad_adjudicada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFGv9fgjDeao"
   },
   "source": [
    "## A DataFrame as an array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNxJ41MafiB-"
   },
   "source": [
    "If your data has a uniform datatype, or `dtype`, it's possible to use a pandas DataFrame anywhere you could use a NumPy array. This works because the `pandas.DataFrame` class supports the `__array__` protocol, and TensorFlow's `tf.convert_to_tensor` function accepts objects that support the protocol.\n",
    "\n",
    "Take the numeric features from the dataset (skip the categorical features for now):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:51.134283Z",
     "iopub.status.busy": "2023-09-30T01:24:51.133919Z",
     "iopub.status.idle": "2023-09-30T01:24:51.141860Z",
     "shell.execute_reply": "2023-09-30T01:24:51.141319Z"
    },
    "id": "b9VlFGAie3K0"
   },
   "outputs": [],
   "source": [
    "numeric_features = df[numeric_feature_names]\n",
    "numeric_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe1CMRvSpR_R"
   },
   "source": [
    "The DataFrame can be converted to a NumPy array using the `DataFrame.values` property or `numpy.array(df)`. To convert it to a tensor, use `tf.convert_to_tensor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:51.144878Z",
     "iopub.status.busy": "2023-09-30T01:24:51.144651Z",
     "iopub.status.idle": "2023-09-30T01:24:51.737838Z",
     "shell.execute_reply": "2023-09-30T01:24:51.737206Z"
    },
    "id": "OVv6Nwc9oDBU"
   },
   "outputs": [],
   "source": [
    "tf.convert_to_tensor(numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iRYvoTrr1_G"
   },
   "source": [
    "In general, if an object can be converted to a tensor with `tf.convert_to_tensor` it can be passed anywhere you can pass a `tf.Tensor`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVF7_Z-Mp-qD"
   },
   "source": [
    "### With Model.fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vqkc9gIapQNu"
   },
   "source": [
    "A DataFrame, interpreted as a single tensor, can be used directly as an argument to the `Model.fit` method.\n",
    "\n",
    "Below is an example of training a model on the numeric features of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8M3oYHZgH_t"
   },
   "source": [
    "The first step is to normalize the input ranges. Use a `tf.keras.layers.Normalization` layer for that.\n",
    "\n",
    "To set the layer's mean and standard-deviation before running it be sure to call the `Normalization.adapt` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:51.741644Z",
     "iopub.status.busy": "2023-09-30T01:24:51.741204Z",
     "iopub.status.idle": "2023-09-30T01:24:51.966557Z",
     "shell.execute_reply": "2023-09-30T01:24:51.965840Z"
    },
    "id": "88XTmyEdgkJn"
   },
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_D7JqUtnYCnb"
   },
   "source": [
    "Call the layer on the first three rows of the DataFrame to visualize an example of the output from this layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:51.970817Z",
     "iopub.status.busy": "2023-09-30T01:24:51.970241Z",
     "iopub.status.idle": "2023-09-30T01:24:51.981046Z",
     "shell.execute_reply": "2023-09-30T01:24:51.980404Z"
    },
    "id": "jOwzIG-DhB0y"
   },
   "outputs": [],
   "source": [
    "normalizer(numeric_features.iloc[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWKcuVZJh-HY"
   },
   "source": [
    "Use the normalization layer as the first layer of a simple model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:51.984380Z",
     "iopub.status.busy": "2023-09-30T01:24:51.984135Z",
     "iopub.status.idle": "2023-09-30T01:24:51.988260Z",
     "shell.execute_reply": "2023-09-30T01:24:51.987596Z"
    },
    "id": "lu-bni-nh6mX"
   },
   "outputs": [],
   "source": [
    "def get_basic_model():\n",
    "  model = tf.keras.Sequential([\n",
    "    normalizer,\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntGi6ngYitob"
   },
   "source": [
    "When you pass the DataFrame as the `x` argument to `Model.fit`, Keras treats the DataFrame as it would a NumPy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:51.991450Z",
     "iopub.status.busy": "2023-09-30T01:24:51.990878Z",
     "iopub.status.idle": "2023-09-30T01:24:56.025481Z",
     "shell.execute_reply": "2023-09-30T01:24:56.024818Z"
    },
    "id": "XMjM-eddiNNT"
   },
   "outputs": [],
   "source": [
    "model = get_basic_model()\n",
    "model.fit(numeric_features, target, epochs=15, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjtQbsRPEoJT"
   },
   "source": [
    "### With tf.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSjV5gy3EsVv"
   },
   "source": [
    "If you want to apply `tf.data` transformations to a DataFrame of a uniform `dtype`, the `Dataset.from_tensor_slices` method will create a dataset that iterates over the rows of the DataFrame. Each row is initially a vector of values. To train a model, you need `(inputs, labels)` pairs, so pass `(features, labels)` and `Dataset.from_tensor_slices` will return the needed pairs of slices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:56.029187Z",
     "iopub.status.busy": "2023-09-30T01:24:56.028655Z",
     "iopub.status.idle": "2023-09-30T01:24:56.048608Z",
     "shell.execute_reply": "2023-09-30T01:24:56.047866Z"
    },
    "id": "FCphpgdRGikx"
   },
   "outputs": [],
   "source": [
    "numeric_dataset = tf.data.Dataset.from_tensor_slices((numeric_features, target))\n",
    "\n",
    "for row in numeric_dataset.take(3):\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:56.051984Z",
     "iopub.status.busy": "2023-09-30T01:24:56.051451Z",
     "iopub.status.idle": "2023-09-30T01:24:59.752197Z",
     "shell.execute_reply": "2023-09-30T01:24:59.751487Z"
    },
    "id": "lStkN86gEkCe"
   },
   "outputs": [],
   "source": [
    "numeric_batches = numeric_dataset.shuffle(1000).batch(BATCH_SIZE)\n",
    "\n",
    "model = get_basic_model()\n",
    "model.fit(numeric_batches, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRASs9IIESWQ"
   },
   "source": [
    "## A DataFrame as a dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NQcp7kiPF8TP"
   },
   "source": [
    "When you start dealing with heterogeneous data, it is no longer possible to treat the DataFrame as if it were a single array. TensorFlow tensors require that all elements have the same `dtype`.\n",
    "\n",
    "So, in this case, you need to start treating it as a dictionary of columns, where each column has a uniform `dtype`. A DataFrame is a lot like a dictionary of arrays, so typically all you need to do is cast the DataFrame to a Python dict. Many important TensorFlow APIs support (nested-)dictionaries of arrays as inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9y5UMKL8bury"
   },
   "source": [
    "`tf.data` input pipelines handle this quite well. All `tf.data` operations handle dictionaries and tuples automatically. So, to make a dataset of dictionary-examples from a DataFrame, just cast it to a dict before slicing it with `Dataset.from_tensor_slices`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:59.756052Z",
     "iopub.status.busy": "2023-09-30T01:24:59.755411Z",
     "iopub.status.idle": "2023-09-30T01:24:59.765224Z",
     "shell.execute_reply": "2023-09-30T01:24:59.764638Z"
    },
    "id": "U3QDo-jwHYXc"
   },
   "outputs": [],
   "source": [
    "numeric_dict_ds = tf.data.Dataset.from_tensor_slices((dict(numeric_features), target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyEERK9ldIi_"
   },
   "source": [
    "Here are the first three examples from that dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:59.768542Z",
     "iopub.status.busy": "2023-09-30T01:24:59.768074Z",
     "iopub.status.idle": "2023-09-30T01:24:59.781389Z",
     "shell.execute_reply": "2023-09-30T01:24:59.780803Z"
    },
    "id": "q0tDwk0VdH6D"
   },
   "outputs": [],
   "source": [
    "for row in numeric_dict_ds.take(3):\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DEAM6HAFxlMy"
   },
   "source": [
    "### Dictionaries with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnoyoWLWx07i"
   },
   "source": [
    "Typically, Keras models and layers expect a single input tensor, but these classes can accept and return nested structures of dictionaries, tuples and tensors. These structures are known as \"nests\" (refer to the `tf.nest` module for details).\n",
    "\n",
    "There are two equivalent ways you can write a Keras model that accepts a dictionary as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xUTrm0apDTr"
   },
   "source": [
    "#### 1. The Model-subclass style\n",
    "\n",
    "You write a subclass of `tf.keras.Model` (or `tf.keras.Layer`). You directly handle the inputs, and create the outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:59.785049Z",
     "iopub.status.busy": "2023-09-30T01:24:59.784448Z",
     "iopub.status.idle": "2023-09-30T01:24:59.788318Z",
     "shell.execute_reply": "2023-09-30T01:24:59.787666Z"
    },
    "id": "Zc3HV99CFRWL"
   },
   "outputs": [],
   "source": [
    "def stack_dict(inputs, fun=tf.stack):\n",
    "  values = []\n",
    "  for key in sorted(inputs.keys()):\n",
    "    values.append(tf.cast(inputs[key], tf.float32))\n",
    "  return fun(values, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:59.791789Z",
     "iopub.status.busy": "2023-09-30T01:24:59.791260Z",
     "iopub.status.idle": "2023-09-30T01:24:59.977513Z",
     "shell.execute_reply": "2023-09-30T01:24:59.976845Z"
    },
    "id": "Rz4Cg6WpzNzi"
   },
   "outputs": [],
   "source": [
    "#@title\n",
    "class MyModel(tf.keras.Model):\n",
    "  def __init__(self):\n",
    "    # Create all the internal layers in init.\n",
    "    super().__init__()\n",
    "\n",
    "    self.normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "\n",
    "    self.seq = tf.keras.Sequential([\n",
    "      self.normalizer,\n",
    "      tf.keras.layers.Dense(10, activation='relu'),\n",
    "      tf.keras.layers.Dense(10, activation='relu'),\n",
    "      tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "  def adapt(self, inputs):\n",
    "    # Stack the inputs and `adapt` the normalization layer.\n",
    "    inputs = stack_dict(inputs)\n",
    "    self.normalizer.adapt(inputs)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    # Stack the inputs\n",
    "    inputs = stack_dict(inputs)\n",
    "    # Run them through all the layers.\n",
    "    result = self.seq(inputs)\n",
    "\n",
    "    return result\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "model.adapt(dict(numeric_features))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'],\n",
    "              run_eagerly=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hMLXNEDF_tu2"
   },
   "source": [
    "This model can accept either a dictionary of columns or a dataset of dictionary-elements for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:24:59.981891Z",
     "iopub.status.busy": "2023-09-30T01:24:59.981285Z",
     "iopub.status.idle": "2023-09-30T01:25:17.171226Z",
     "shell.execute_reply": "2023-09-30T01:25:17.170533Z"
    },
    "id": "v3xEjtHY8gZG"
   },
   "outputs": [],
   "source": [
    "model.fit(dict(numeric_features), target, epochs=5, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:25:17.174886Z",
     "iopub.status.busy": "2023-09-30T01:25:17.174308Z",
     "iopub.status.idle": "2023-09-30T01:25:32.439227Z",
     "shell.execute_reply": "2023-09-30T01:25:32.438550Z"
    },
    "id": "73wgiTaVAA2F"
   },
   "outputs": [],
   "source": [
    "numeric_dict_batches = numeric_dict_ds.shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "model.fit(numeric_dict_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-xDB3HLZGzAb"
   },
   "source": [
    "Here are the predictions for the first three examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:25:32.442701Z",
     "iopub.status.busy": "2023-09-30T01:25:32.442420Z",
     "iopub.status.idle": "2023-09-30T01:25:32.521687Z",
     "shell.execute_reply": "2023-09-30T01:25:32.521024Z"
    },
    "id": "xtolTQA-GpBW"
   },
   "outputs": [],
   "source": [
    "model.predict(dict(numeric_features.iloc[:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIIdxIYm13Ik"
   },
   "source": [
    "#### 2. The Keras functional style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:25:32.525579Z",
     "iopub.status.busy": "2023-09-30T01:25:32.524813Z",
     "iopub.status.idle": "2023-09-30T01:25:32.534838Z",
     "shell.execute_reply": "2023-09-30T01:25:32.534184Z"
    },
    "id": "DG_bmO0sS_G5"
   },
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "for name, column in numeric_features.items():\n",
    "  inputs[name] = tf.keras.Input(\n",
    "      shape=(1,), name=name, dtype=tf.float32)\n",
    "\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:25:32.538333Z",
     "iopub.status.busy": "2023-09-30T01:25:32.537628Z",
     "iopub.status.idle": "2023-09-30T01:25:32.752640Z",
     "shell.execute_reply": "2023-09-30T01:25:32.751866Z"
    },
    "id": "9iXU9oem12dL"
   },
   "outputs": [],
   "source": [
    "x = stack_dict(inputs, fun=tf.concat)\n",
    "\n",
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(stack_dict(dict(numeric_features)))\n",
    "\n",
    "x = normalizer(x)\n",
    "x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(10, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, x)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'],\n",
    "              run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:25:32.756540Z",
     "iopub.status.busy": "2023-09-30T01:25:32.756029Z",
     "iopub.status.idle": "2023-09-30T01:25:32.916755Z",
     "shell.execute_reply": "2023-09-30T01:25:32.915908Z"
    },
    "id": "xrAxmuJrEwnf"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, rankdir=\"LR\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYtoAOIzCFY1"
   },
   "source": [
    "You can train the functional model the same way as the model subclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:25:32.920710Z",
     "iopub.status.busy": "2023-09-30T01:25:32.920435Z",
     "iopub.status.idle": "2023-09-30T01:25:49.140252Z",
     "shell.execute_reply": "2023-09-30T01:25:49.139512Z"
    },
    "id": "yAwjPq7I_ehX"
   },
   "outputs": [],
   "source": [
    "model.fit(dict(numeric_features), target, epochs=5, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:25:49.144037Z",
     "iopub.status.busy": "2023-09-30T01:25:49.143327Z",
     "iopub.status.idle": "2023-09-30T01:26:05.443667Z",
     "shell.execute_reply": "2023-09-30T01:26:05.442949Z"
    },
    "id": "brwodxxVApO_"
   },
   "outputs": [],
   "source": [
    "numeric_dict_batches = numeric_dict_ds.shuffle(SHUFFLE_BUFFER).batch(BATCH_SIZE)\n",
    "model.fit(numeric_dict_batches, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhn0Bt_Xw4nO"
   },
   "source": [
    "## Full example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zYQ5fDaRxRWQ"
   },
   "source": [
    "If you're passing a heterogeneous DataFrame to Keras, each column may need unique preprocessing. You could do this preprocessing directly in the DataFrame, but for a model to work correctly, inputs always need to be preprocessed the same way. So, the best approach is to build the preprocessing into the model. [Keras preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers) cover many common tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BFsDZeu-BQ-h"
   },
   "source": [
    "### Build the preprocessing head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6aVQN4Gw-Va"
   },
   "source": [
    "In this dataset some of the \"integer\" features in the raw data are actually Categorical indices. These indices are not really ordered numeric values (refer to the <a href=\"https://archive.ics.uci.edu/ml/datasets/heart+Disease\" class=\"external\">the dataset description</a> for details). Because these are unordered they are inappropriate to feed directly to the model; the model would interpret them as being ordered. To use these inputs you'll need to encode them, either as one-hot vectors or embedding vectors. The same applies to string-categorical features.\n",
    "\n",
    "Note: If you have many features that need identical preprocessing it's more efficient to concatenate them together before applying the preprocessing.\n",
    "\n",
    "Binary features on the other hand do not generally need to be encoded or normalized.\n",
    "\n",
    "Start by by creating a list of the features that fall into each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.447812Z",
     "iopub.status.busy": "2023-09-30T01:26:05.447192Z",
     "iopub.status.idle": "2023-09-30T01:26:05.450767Z",
     "shell.execute_reply": "2023-09-30T01:26:05.450171Z"
    },
    "id": "IH2VCyLBPYX8"
   },
   "outputs": [],
   "source": [
    "# binary_feature_names = ['sex', 'fbs', 'exang']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.454091Z",
     "iopub.status.busy": "2023-09-30T01:26:05.453496Z",
     "iopub.status.idle": "2023-09-30T01:26:05.456950Z",
     "shell.execute_reply": "2023-09-30T01:26:05.456358Z"
    },
    "id": "Pxh4FPucOpDz"
   },
   "outputs": [],
   "source": [
    "# categorical_feature_names = ['cp', 'restecg', 'slope', 'thal', 'ca']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRcC8WkyamJb"
   },
   "source": [
    "The next step is to build a preprocessing model that will apply appropriate preprocessing to each input and concatenate the results.\n",
    "\n",
    "This section uses the [Keras Functional API](https://www.tensorflow.org/guide/keras/functional) to implement  the preprocessing. You start by creating one `tf.keras.Input` for each column of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.459947Z",
     "iopub.status.busy": "2023-09-30T01:26:05.459334Z",
     "iopub.status.idle": "2023-09-30T01:26:05.476173Z",
     "shell.execute_reply": "2023-09-30T01:26:05.475548Z"
    },
    "id": "D3OeiteJbWvI"
   },
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "for name, column in df.items():\n",
    "  if type(column[0]) == str:\n",
    "    dtype = tf.string\n",
    "  elif (name in categorical_feature_names or\n",
    "        name in binary_feature_names):\n",
    "    dtype = tf.int64\n",
    "  else:\n",
    "    dtype = tf.float32\n",
    "\n",
    "  inputs[name] = tf.keras.Input(shape=(), name=name, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.478955Z",
     "iopub.status.busy": "2023-09-30T01:26:05.478570Z",
     "iopub.status.idle": "2023-09-30T01:26:05.483112Z",
     "shell.execute_reply": "2023-09-30T01:26:05.482556Z"
    },
    "id": "5N3vBMjidpx6"
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EEmzxinyhI4"
   },
   "source": [
    "For each input you'll apply some transformations using Keras layers and TensorFlow ops. Each feature starts as a batch of scalars (`shape=(batch,)`). The output for each  should be a batch of `tf.float32` vectors (`shape=(batch, n)`). The last step will concatenate all those vectors together.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ubBDazjNFWiF"
   },
   "source": [
    "#### Binary inputs\n",
    "\n",
    "Since the binary inputs don't need any preprocessing, just add the vector axis, cast them to `float32` and add them to the list of preprocessed inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.486388Z",
     "iopub.status.busy": "2023-09-30T01:26:05.485849Z",
     "iopub.status.idle": "2023-09-30T01:26:05.510037Z",
     "shell.execute_reply": "2023-09-30T01:26:05.509481Z"
    },
    "id": "tmAIkOIid-Mp"
   },
   "outputs": [],
   "source": [
    "preprocessed = []\n",
    "\n",
    "for name in binary_feature_names:\n",
    "  inp = inputs[name]\n",
    "  inp = inp[:, tf.newaxis]\n",
    "  float_value = tf.cast(inp, tf.float32)\n",
    "  preprocessed.append(float_value)\n",
    "\n",
    "preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHQcdtG1GN7E"
   },
   "source": [
    "#### Numeric inputs\n",
    "\n",
    "Like in the earlier section you'll want to run these numeric inputs through a `tf.keras.layers.Normalization` layer before using them. The difference is that this time they're input as a dict. The code below collects the numeric features from the DataFrame, stacks them together and passes those to the `Normalization.adapt` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.512695Z",
     "iopub.status.busy": "2023-09-30T01:26:05.512470Z",
     "iopub.status.idle": "2023-09-30T01:26:05.681986Z",
     "shell.execute_reply": "2023-09-30T01:26:05.681223Z"
    },
    "id": "UC9LaIBNIK5V"
   },
   "outputs": [],
   "source": [
    "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalizer.adapt(stack_dict(dict(numeric_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S537tideIpeh"
   },
   "source": [
    "The code below stacks the numeric features and runs them through the normalization layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.686139Z",
     "iopub.status.busy": "2023-09-30T01:26:05.685495Z",
     "iopub.status.idle": "2023-09-30T01:26:05.710331Z",
     "shell.execute_reply": "2023-09-30T01:26:05.709698Z"
    },
    "id": "U8MJiFpPK5uD"
   },
   "outputs": [],
   "source": [
    "numeric_inputs = {}\n",
    "for name in numeric_feature_names:\n",
    "  numeric_inputs[name]=inputs[name]\n",
    "\n",
    "numeric_inputs = stack_dict(numeric_inputs)\n",
    "numeric_normalized = normalizer(numeric_inputs)\n",
    "\n",
    "preprocessed.append(numeric_normalized)\n",
    "\n",
    "preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5f-VzASKPF7"
   },
   "source": [
    "#### Categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z3wcFs1oKVao"
   },
   "source": [
    "To use categorical features you'll first need to encode them into either binary vectors or embeddings. Since these features only contain a small number of categories, convert the inputs directly to one-hot vectors using the `output_mode='one_hot'` option, supported by both the `tf.keras.layers.StringLookup` and `tf.keras.layers.IntegerLookup` layers.\n",
    "\n",
    "Here is an example of how these layers work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.713889Z",
     "iopub.status.busy": "2023-09-30T01:26:05.713269Z",
     "iopub.status.idle": "2023-09-30T01:26:05.737045Z",
     "shell.execute_reply": "2023-09-30T01:26:05.736418Z"
    },
    "id": "vXleJfBRS9xr"
   },
   "outputs": [],
   "source": [
    "vocab = ['a','b','c']\n",
    "lookup = tf.keras.layers.StringLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "lookup(['c','a','a','b','zzz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.739853Z",
     "iopub.status.busy": "2023-09-30T01:26:05.739601Z",
     "iopub.status.idle": "2023-09-30T01:26:05.753143Z",
     "shell.execute_reply": "2023-09-30T01:26:05.752499Z"
    },
    "id": "kRnsFYJiSVmH"
   },
   "outputs": [],
   "source": [
    "vocab = [1,4,7,99]\n",
    "lookup = tf.keras.layers.IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "\n",
    "lookup([-1,4,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "est6aCFBZDVs"
   },
   "source": [
    "To determine the vocabulary for each input, create a layer to convert that vocabulary to a one-hot vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.756240Z",
     "iopub.status.busy": "2023-09-30T01:26:05.755976Z",
     "iopub.status.idle": "2023-09-30T01:26:05.847332Z",
     "shell.execute_reply": "2023-09-30T01:26:05.846664Z"
    },
    "id": "HELhoFlo0H9Q"
   },
   "outputs": [],
   "source": [
    "for name in categorical_feature_names:\n",
    "  vocab = sorted(set(df[name]))\n",
    "  print(f'name: {name}')\n",
    "  print(f'vocab: {vocab}\\n')\n",
    "\n",
    "  if type(vocab[0]) is str:\n",
    "    lookup = tf.keras.layers.StringLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "  else:\n",
    "    lookup = tf.keras.layers.IntegerLookup(vocabulary=vocab, output_mode='one_hot')\n",
    "\n",
    "  x = inputs[name][:, tf.newaxis]\n",
    "  x = lookup(x)\n",
    "  preprocessed.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzMMkwNBa2pK"
   },
   "source": [
    "#### Assemble the preprocessing head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GaQ-_pEQbCE8"
   },
   "source": [
    "At this point `preprocessed` is just a Python list of all the preprocessing results, each result has a shape of `(batch_size, depth)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.851471Z",
     "iopub.status.busy": "2023-09-30T01:26:05.850821Z",
     "iopub.status.idle": "2023-09-30T01:26:05.855599Z",
     "shell.execute_reply": "2023-09-30T01:26:05.854922Z"
    },
    "id": "LlLaq_BVRlnO"
   },
   "outputs": [],
   "source": [
    "preprocessed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9lYYHIXbYv-"
   },
   "source": [
    "Concatenate all the preprocessed features along the `depth` axis, so each dictionary-example is converted into a single vector. The vector contains categorical features, numeric features, and categorical one-hot features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.858917Z",
     "iopub.status.busy": "2023-09-30T01:26:05.858276Z",
     "iopub.status.idle": "2023-09-30T01:26:05.869927Z",
     "shell.execute_reply": "2023-09-30T01:26:05.869347Z"
    },
    "id": "j2I8vpQh313w"
   },
   "outputs": [],
   "source": [
    "preprocesssed_result = tf.concat(preprocessed, axis=-1)\n",
    "preprocesssed_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBFowyJtb0WB"
   },
   "source": [
    "Now create a model out of that calculation so it can be reused:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.873289Z",
     "iopub.status.busy": "2023-09-30T01:26:05.872691Z",
     "iopub.status.idle": "2023-09-30T01:26:05.881723Z",
     "shell.execute_reply": "2023-09-30T01:26:05.881126Z"
    },
    "id": "rHQBFHwE37TO"
   },
   "outputs": [],
   "source": [
    "preprocessor = tf.keras.Model(inputs, preprocesssed_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:05.885182Z",
     "iopub.status.busy": "2023-09-30T01:26:05.884549Z",
     "iopub.status.idle": "2023-09-30T01:26:06.376353Z",
     "shell.execute_reply": "2023-09-30T01:26:06.375409Z"
    },
    "id": "ViMARQ-f6zfx"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(preprocessor, rankdir=\"LR\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IURRtL_WZbht"
   },
   "source": [
    "To test the preprocessor, use the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html\" class=\"external\">DataFrame.iloc</a> accessor to slice the first example from the DataFrame. Then convert it to a dictionary and pass the dictionary to the preprocessor. The result is a single vector containing the binary features, normalized numeric features and the one-hot categorical features, in that order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:06.382867Z",
     "iopub.status.busy": "2023-09-30T01:26:06.382226Z",
     "iopub.status.idle": "2023-09-30T01:26:06.413798Z",
     "shell.execute_reply": "2023-09-30T01:26:06.413139Z"
    },
    "id": "QjBzCKsZUj0y"
   },
   "outputs": [],
   "source": [
    "preprocessor(dict(df.iloc[:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bB9C0XJkyQEk"
   },
   "source": [
    "### Create and train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfU_FFXMbKGM"
   },
   "source": [
    "Now build the main body of the model. Use the same configuration as in the previous example: A couple of `Dense` rectified-linear layers and a `Dense(1)` output layer for the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:06.416953Z",
     "iopub.status.busy": "2023-09-30T01:26:06.416722Z",
     "iopub.status.idle": "2023-09-30T01:26:06.426685Z",
     "shell.execute_reply": "2023-09-30T01:26:06.426079Z"
    },
    "id": "75OxXTnfboKN"
   },
   "outputs": [],
   "source": [
    "body = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation='relu'),\n",
    "  tf.keras.layers.Dense(10, activation='relu'),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpD6WNX5_zh5"
   },
   "source": [
    "Now put the two pieces together using the Keras functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:06.430210Z",
     "iopub.status.busy": "2023-09-30T01:26:06.429655Z",
     "iopub.status.idle": "2023-09-30T01:26:06.434201Z",
     "shell.execute_reply": "2023-09-30T01:26:06.433576Z"
    },
    "id": "_TY_BuVMbNcB"
   },
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:06.437266Z",
     "iopub.status.busy": "2023-09-30T01:26:06.436799Z",
     "iopub.status.idle": "2023-09-30T01:26:06.516419Z",
     "shell.execute_reply": "2023-09-30T01:26:06.515721Z"
    },
    "id": "iin2kvA9bDpz"
   },
   "outputs": [],
   "source": [
    "x = preprocessor(inputs)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:06.519153Z",
     "iopub.status.busy": "2023-09-30T01:26:06.518937Z",
     "iopub.status.idle": "2023-09-30T01:26:06.556555Z",
     "shell.execute_reply": "2023-09-30T01:26:06.555955Z"
    },
    "id": "FQd9PcPRpkP4"
   },
   "outputs": [],
   "source": [
    "result = body(x)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:06.559500Z",
     "iopub.status.busy": "2023-09-30T01:26:06.559061Z",
     "iopub.status.idle": "2023-09-30T01:26:06.571700Z",
     "shell.execute_reply": "2023-09-30T01:26:06.571111Z"
    },
    "id": "v_KerrXabhgP"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs, result)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1MR-XD9kC6C"
   },
   "source": [
    "This model expects a dictionary of inputs. The simplest way to pass it the data is to convert the DataFrame to a dict and pass that dict as the `x` argument to `Model.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:06.574980Z",
     "iopub.status.busy": "2023-09-30T01:26:06.574508Z",
     "iopub.status.idle": "2023-09-30T01:26:08.882091Z",
     "shell.execute_reply": "2023-09-30T01:26:08.881326Z"
    },
    "id": "ybDzNUheqxJw"
   },
   "outputs": [],
   "source": [
    "history = model.fit(dict(df), target, epochs=5, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dacoEIB_BSsL"
   },
   "source": [
    "Using `tf.data` works as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:08.885634Z",
     "iopub.status.busy": "2023-09-30T01:26:08.885358Z",
     "iopub.status.idle": "2023-09-30T01:26:08.903387Z",
     "shell.execute_reply": "2023-09-30T01:26:08.902787Z"
    },
    "id": "rYadV3wwE4G3"
   },
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(df),\n",
    "    target\n",
    "))\n",
    "\n",
    "ds = ds.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:08.906698Z",
     "iopub.status.busy": "2023-09-30T01:26:08.906231Z",
     "iopub.status.idle": "2023-09-30T01:26:08.923113Z",
     "shell.execute_reply": "2023-09-30T01:26:08.922475Z"
    },
    "id": "2YIpp2r0bv-6"
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "for x, y in ds.take(1):\n",
    "  pprint.pprint(x)\n",
    "  print()\n",
    "  print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-30T01:26:08.926528Z",
     "iopub.status.busy": "2023-09-30T01:26:08.925928Z",
     "iopub.status.idle": "2023-09-30T01:26:10.780124Z",
     "shell.execute_reply": "2023-09-30T01:26:10.779220Z"
    },
    "id": "NMT-AevGFmdu"
   },
   "outputs": [],
   "source": [
    "history = model.fit(ds, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "pandas_dataframe.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
